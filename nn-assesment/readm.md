### make_blobs functtion
<!-- The function creates datapoints (random coordinates).
Then it splits them into two groups:
Left blob = class 0 â†’ label 0
Right blob = class 1 â†’ label 1
So you end up with:
X â†’ the points (features the model will use).
y â†’ the class labels (the answers the model should learn).
ðŸ‘‰ That way, when we train the neural network, it can learn:
â€œPoints on the left are class 0, points on the right are class 1.â€ -->


### class MLP  (Input â†’ Hidden Layer 1 â†’ ReLU â†’ Hidden Layer 2 â†’ ReLU â†’ Output â†’ Logit)
<!-- MLP is a neural network model inheriting from nn.Module, which is the base class for all PyTorch models.

This means it can:

Store layers as attributes.

Automatically track parameters for optimization.

Define a forward method to compute outputs from inputs. -->

<!-- forward defines how data moves through the network.
forward defines how data flows through the network.
x is a batch of input features: shape [batch_size, in_dim].
self.net(x) applies all layers sequentially.
.squeeze(1) removes the extra dimension from the output:
nn.Linear(..., 1) gives shape [batch_size, 1].
squeeze(1) converts it to [batch_size].-->

### Data Class
<!-- 3ï¸âƒ£ Advantages of @dataclass
Less boilerplate â€“ no need to manually define __init__ or __repr__.
Clear structure â€“ makes your hyperparameters look like a clean, immutable â€œrecordâ€.
Easy to modify defaults â€“ can easily create variants: -->
<!-- 
A normal class can be used to define entities with behavior, logic, and custom methods. A data class focuses on storing and processing data with minimal code -->

# Learning Rate
<!-- Learning rate for the optimizer (0.01).

Controls how big a step the model takes while updating weights. -->



![alt text](image.png)





### nn.Conv2d(1, 32, kernel_size=3, padding=1),  
<!-- What are these 32 shapes?

Each little 3Ã—3 square is one kernel (filter) that your CNN learned automatically during training.

The network doesnâ€™t know digits at first.

It only knows: â€œI have 32 little 3Ã—3 windows that I can adjust.â€

Training adjusts these tiny windows so that they become pattern detectors.

What patterns do they detect?

At this first layer, they are very simple:

Vertical edges (dark on left, light on right)

Horizontal edges (dark on top, light on bottom)

Diagonals (slanted strokes)

Blobs (spots of light/dark)

So each kernel specializes in looking for one type of feature anywhere in the image.

Why do we need 32 different ones?

Because a digit has many possible local features:

The vertical bar of â€œ1â€

The loop in â€œ0â€

The diagonal of â€œ7â€

The horizontal top of â€œ5â€

One filter canâ€™t detect all of them.
ðŸ‘‰ So the CNN learns a whole set of 32 filters, each focusing on different simple patterns. -->